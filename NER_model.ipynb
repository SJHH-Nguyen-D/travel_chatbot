{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER_model.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "yPj0T71h5Vl9",
        "L6F_mTQzFnSP",
        "DvNQtNPVG49I",
        "5IlAyS8PPVov",
        "kdNT9auiRoKO",
        "WpQCZqm1u8Rp",
        "EFm2B4ef16DS"
      ],
      "mount_file_id": "1OYlG4YphGkIwLI0Nnqv9HIGc-UdKa7-v",
      "authorship_tag": "ABX9TyO8egkz1YVJ796I9DZ7GCT/"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttHOzxT3LRCT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ! sudo apt install openjdk-8-jdk\n",
        "# ! sudo update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java \n",
        "# ! pip install language-check -qq\n",
        "# ! pip install pycontractions -qq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYilNPsPjxYn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8fe8131d-5923-4fc1-9c37-600ee81154b2"
      },
      "source": [
        "! pip install chatterbot \n",
        "! pip install chatterbot_corpus"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting chatterbot\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/0e/dac0d82f34f86bf509cf5ef3e2dfc5aa7d444bd843a2330ceb7d854f84f2/ChatterBot-1.0.5-py2.py3-none-any.whl (67kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 2.3MB/s \n",
            "\u001b[?25hCollecting pyyaml<5.2,>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/e8/b3212641ee2718d556df0f23f78de8303f068fe29cdaa7a91018849582fe/PyYAML-5.1.2.tar.gz (265kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk<4.0,>=3.2 in /usr/local/lib/python3.6/dist-packages (from chatterbot) (3.2.5)\n",
            "Requirement already satisfied: pymongo<4.0,>=3.3 in /usr/local/lib/python3.6/dist-packages (from chatterbot) (3.10.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from chatterbot) (2018.9)\n",
            "Collecting python-dateutil<2.8,>=2.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/68/d87d9b36af36f44254a8d512cbfc48369103a3b9e474be9bdfe536abfc45/python_dateutil-2.7.5-py2.py3-none-any.whl (225kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 19.2MB/s \n",
            "\u001b[?25hCollecting sqlalchemy<1.3,>=1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/67/d07cf7ac7e6dd0bc55ba62816753f86d7c558107104ca915e730c9ec2512/SQLAlchemy-1.2.19.tar.gz (5.7MB)\n",
            "\u001b[K     |████████████████████████████████| 5.7MB 16.8MB/s \n",
            "\u001b[?25hCollecting pint>=0.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/db/7a2204b03c22069839958df5723eb2718d50c33052e0da84c9a83de14ea4/Pint-0.11-py2.py3-none-any.whl (186kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 44.2MB/s \n",
            "\u001b[?25hCollecting mathparse<0.2,>=0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/c3/e5/4910fb85950cb960fcf3f5aabe1c8e55f5c9201788a1c1302b570a7e1f84/mathparse-0.1.2-py3-none-any.whl\n",
            "Collecting spacy<2.2,>=2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/5b/e07dd3bf104237bce4b398558b104c8e500333d6f30eabe3fa9685356b7d/spacy-2.1.9-cp36-cp36m-manylinux1_x86_64.whl (30.8MB)\n",
            "\u001b[K     |████████████████████████████████| 30.9MB 106kB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk<4.0,>=3.2->chatterbot) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pint>=0.8.1->chatterbot) (46.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1->chatterbot) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1->chatterbot) (2.0.3)\n",
            "Collecting preshed<2.1.0,>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/93/f222fb957764a283203525ef20e62008675fd0a14ffff8cc1b1490147c63/preshed-2.0.1-cp36-cp36m-manylinux1_x86_64.whl (83kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 12.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1->chatterbot) (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1->chatterbot) (1.18.2)\n",
            "Collecting thinc<7.1.0,>=7.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/a5/9ace20422e7bb1bdcad31832ea85c52a09900cd4a7ce711246bfb92206ba/thinc-7.0.8-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 57.7MB/s \n",
            "\u001b[?25hCollecting blis<0.3.0,>=0.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/46/b1d0bb71d308e820ed30316c5f0a017cb5ef5f4324bcbc7da3cf9d3b075c/blis-0.2.4-cp36-cp36m-manylinux1_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 38.9MB/s \n",
            "\u001b[?25hCollecting plac<1.0.0,>=0.9.6\n",
            "  Downloading https://files.pythonhosted.org/packages/9e/9b/62c60d2f5bc135d2aa1d8c8a86aaf84edb719a59c7f11a4316259e61a298/plac-0.9.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1->chatterbot) (1.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1->chatterbot) (2.21.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.8->spacy<2.2,>=2.1->chatterbot) (4.38.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2,>=2.1->chatterbot) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2,>=2.1->chatterbot) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2,>=2.1->chatterbot) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2,>=2.1->chatterbot) (2.8)\n",
            "Building wheels for collected packages: pyyaml, sqlalchemy\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.1.2-cp36-cp36m-linux_x86_64.whl size=44104 sha256=dc23efadbe158bcb975017780cfbfecab339f4a2727322d92cb09755e229b620\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/45/dd/65f0b38450c47cf7e5312883deb97d065e030c5cca0a365030\n",
            "  Building wheel for sqlalchemy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlalchemy: filename=SQLAlchemy-1.2.19-cp36-cp36m-linux_x86_64.whl size=1151141 sha256=0130309e0bb55d213c65054b2e0d6bfb116569e1494a6e82e1eb43590e34dff8\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/90/a7/3b40c6cc468abff357b38fd075429920bd0d313659d889cf8a\n",
            "Successfully built pyyaml sqlalchemy\n",
            "\u001b[31mERROR: fbprophet 0.6 has requirement python-dateutil>=2.8.0, but you'll have python-dateutil 2.7.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: en-core-web-sm 2.2.5 has requirement spacy>=2.2.2, but you'll have spacy 2.1.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pyyaml, python-dateutil, sqlalchemy, pint, mathparse, preshed, blis, plac, thinc, spacy, chatterbot\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: python-dateutil 2.8.1\n",
            "    Uninstalling python-dateutil-2.8.1:\n",
            "      Successfully uninstalled python-dateutil-2.8.1\n",
            "  Found existing installation: SQLAlchemy 1.3.15\n",
            "    Uninstalling SQLAlchemy-1.3.15:\n",
            "      Successfully uninstalled SQLAlchemy-1.3.15\n",
            "  Found existing installation: preshed 3.0.2\n",
            "    Uninstalling preshed-3.0.2:\n",
            "      Successfully uninstalled preshed-3.0.2\n",
            "  Found existing installation: blis 0.4.1\n",
            "    Uninstalling blis-0.4.1:\n",
            "      Successfully uninstalled blis-0.4.1\n",
            "  Found existing installation: plac 1.1.3\n",
            "    Uninstalling plac-1.1.3:\n",
            "      Successfully uninstalled plac-1.1.3\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed blis-0.2.4 chatterbot-1.0.5 mathparse-0.1.2 pint-0.11 plac-0.9.6 preshed-2.0.1 python-dateutil-2.7.5 pyyaml-5.1.2 spacy-2.1.9 sqlalchemy-1.2.19 thinc-7.0.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting chatterbot_corpus\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/19/f8b41daf36fe4b0f43e283a820362ffdb2c1128600ab4ee187e84262fa4d/chatterbot_corpus-1.2.0-py2.py3-none-any.whl (117kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 3.5MB/s \n",
            "\u001b[?25hCollecting PyYAML<4.0,>=3.12\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/a3/1d13970c3f36777c583f136c136f804d70f500168edc1edea6daa7200769/PyYAML-3.13.tar.gz (270kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 38.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: PyYAML\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyYAML: filename=PyYAML-3.13-cp36-cp36m-linux_x86_64.whl size=43086 sha256=791aede517b44281288b0ec69aa4c59da68d68e495a748acfc592dcb9c804abb\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/da/0c/74eb680767247273e2cf2723482cb9c924fe70af57c334513f\n",
            "Successfully built PyYAML\n",
            "\u001b[31mERROR: chatterbot 1.0.5 has requirement pyyaml<5.2,>=5.1, but you'll have pyyaml 3.13 which is incompatible.\u001b[0m\n",
            "Installing collected packages: PyYAML, chatterbot-corpus\n",
            "  Found existing installation: PyYAML 5.1.2\n",
            "    Uninstalling PyYAML-5.1.2:\n",
            "      Successfully uninstalled PyYAML-5.1.2\n",
            "Successfully installed PyYAML-3.13 chatterbot-corpus-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j15dAlF_sKtB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "0ad3a611-6337-4755-c46a-4805e62a68c1"
      },
      "source": [
        "! pip install --upgrade chatterbot \n",
        "! pip install --upgrade chatterbot_corpus"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: chatterbot in /usr/local/lib/python3.6/dist-packages (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil<2.8,>=2.7 in /usr/local/lib/python3.6/dist-packages (from chatterbot) (2.7.5)\n",
            "Requirement already satisfied, skipping upgrade: nltk<4.0,>=3.2 in /usr/local/lib/python3.6/dist-packages (from chatterbot) (3.2.5)\n",
            "Requirement already satisfied, skipping upgrade: pint>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from chatterbot) (0.11)\n",
            "Requirement already satisfied, skipping upgrade: pytz in /usr/local/lib/python3.6/dist-packages (from chatterbot) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: pymongo<4.0,>=3.3 in /usr/local/lib/python3.6/dist-packages (from chatterbot) (3.10.1)\n",
            "Requirement already satisfied, skipping upgrade: spacy<2.2,>=2.1 in /usr/local/lib/python3.6/dist-packages (from chatterbot) (2.1.9)\n",
            "Requirement already satisfied, skipping upgrade: sqlalchemy<1.3,>=1.2 in /usr/local/lib/python3.6/dist-packages (from chatterbot) (1.2.19)\n",
            "Requirement already satisfied, skipping upgrade: mathparse<0.2,>=0.1 in /usr/local/lib/python3.6/dist-packages (from chatterbot) (0.1.2)\n",
            "Processing /root/.cache/pip/wheels/d9/45/dd/65f0b38450c47cf7e5312883deb97d065e030c5cca0a365030/PyYAML-5.1.2-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<2.8,>=2.7->chatterbot) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from pint>=0.8.1->chatterbot) (46.0.0)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1->chatterbot) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1->chatterbot) (7.0.8)\n",
            "Requirement already satisfied, skipping upgrade: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1->chatterbot) (2.0.1)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1->chatterbot) (0.9.6)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1->chatterbot) (1.18.2)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1->chatterbot) (0.6.0)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1->chatterbot) (2.0.3)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1->chatterbot) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1->chatterbot) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1->chatterbot) (0.2.4)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2,>=2.1->chatterbot) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2,>=2.1->chatterbot) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2,>=2.1->chatterbot) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2,>=2.1->chatterbot) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.8->spacy<2.2,>=2.1->chatterbot) (4.38.0)\n",
            "\u001b[31mERROR: chatterbot-corpus 1.2.0 has requirement PyYAML<4.0,>=3.12, but you'll have pyyaml 5.1.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pyyaml\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed pyyaml-5.1.2\n",
            "Requirement already up-to-date: chatterbot_corpus in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Processing /root/.cache/pip/wheels/ad/da/0c/74eb680767247273e2cf2723482cb9c924fe70af57c334513f/PyYAML-3.13-cp36-cp36m-linux_x86_64.whl\n",
            "\u001b[31mERROR: chatterbot 1.0.5 has requirement pyyaml<5.2,>=5.1, but you'll have pyyaml 3.13 which is incompatible.\u001b[0m\n",
            "Installing collected packages: PyYAML\n",
            "  Found existing installation: PyYAML 5.1.2\n",
            "    Uninstalling PyYAML-5.1.2:\n",
            "      Successfully uninstalled PyYAML-5.1.2\n",
            "Successfully installed PyYAML-3.13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krjAXNNE_pGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import statements\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pprint as pp\n",
        "import json\n",
        "from pandas.io.json import json_normalize\n",
        "import re\n",
        "from timeit import default_timer\n",
        "\n",
        "# Preprocessing\n",
        "# from pycontractions import Contractions\n",
        "\n",
        "# Tokenization imports\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Puncuation & lower case\n",
        "import string #punctuation removal\n",
        "\n",
        "# Stop words\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Stemming\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "# Lemmatizer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "# POS tagging\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "# NER\n",
        "import nltk, nltk.tag, nltk.chunk \n",
        "import spacy\n",
        "import pprint as pprint\n",
        "from gensim.summarization import summarize \n",
        "from collections import Counter \n",
        "import en_core_web_sm # CNN gets loaded in, sees what words depends on each other, POS tagging, entity recognition \n",
        "from spacy import displacy # Visualize NER\n",
        "\n",
        "# Chatterbot\n",
        "from chatterbot import ChatBot\n",
        "from chatterbot.trainers import ListTrainer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeAAajV7zKU_",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ju63vJs-FRiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is testing with part 1 - 10% of data\n",
        "with open('/content/drive/My Drive/contraction_data_parts/expand_convo_text_1.txt', 'r') as file:\n",
        "    convo_all = file.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pen9_RKDsJtO",
        "colab_type": "code",
        "outputId": "9848684c-ba0a-4bd3-adaa-0407852d2f52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# Let's see the text data, seems messy \n",
        "# When we extracted conversations from the frames dataset, we split every statement with a new line and every conversations with *\n",
        "# Through the use of pycontractions, every new line (\\n) was added with an extra \\\n",
        "pp.pprint(convo_all[0:1000]) "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('[\"I would like to book a trip to Atlantis from Caprica on Saturday, August '\n",
            " '13, 2016 for 8 adults. I have a tight budget of 1700.\\\\nHi...I checked a few '\n",
            " 'options for you, and unfortunately, we do not currently have any trips that '\n",
            " 'meet this criteria.  Would you like to book an alternate travel '\n",
            " 'option?\\\\nYes, how about going to Neverland from Caprica on August 13, 2016 '\n",
            " 'for 5 adults. For this trip, my budget would be 1900.\\\\nI checked the '\n",
            " 'availability for this date and there were no trips available.  Would you '\n",
            " 'like to select some alternate dates?\\\\nI have no flexibility for dates... '\n",
            " 'but I can leave from Atlantis rather than Caprica. How about that?\\\\nI '\n",
            " 'checked the availability for that date and there were no trips available.  '\n",
            " 'Would you like to select some alternate dates?\\\\nI suppose I will speak with '\n",
            " 'my husband to see if we can choose other dates, and then I will come back to '\n",
            " 'you.Thanks for your help\\\\n******************************************Hello, '\n",
            " 'I am looking to book a vacation from Gotham Ci')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOJOPGk3Xrs6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splits text data into separate lists for each conversation\n",
        "def text_to_convo(text):\n",
        "  list_convos = [convo.split('\\n') for convo in text.split('*') if text]         # Conversation delimited by *\n",
        "  list_convos = [convo for convo in list_convos if convo != ['']]                # Remove empty conversation\n",
        "  return list_convos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrriLBqZoT7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splits all the statements from a conversation into their own string\n",
        "def convo_to_statement(list_convos):\n",
        "  sep_convos = []\n",
        "  for items in list_convos: \n",
        "    sep_convos.append([])                     # Creates list for each conversation\n",
        "    for item in items:\n",
        "      item = item.split('\\\\n')                # Splits conversations into statements \n",
        "      sep_convos[-1].append(item)             # Adds all statements to corresponding list\n",
        "  return sep_convos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bg9ULJTA7WAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Flattens the list as there is a list in another list\n",
        "# - Handles sentence tokenization, as all statements are separated into their own string in this list \n",
        "def flatten_list(sep_convos): \n",
        "  flat_list = []\n",
        "  for convo in sep_convos:\n",
        "    for sublist in convo:\n",
        "      for item in sublist:\n",
        "            flat_list.append(item)\n",
        "  return flat_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPj0T71h5Vl9",
        "colab_type": "text"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xYbWKne5bnM",
        "colab_type": "code",
        "outputId": "aadfb819-3a5b-4561-c2ed-594331f5644f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "nltk.download('punkt') # Punkt sentence tokenizer"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ji6_PAgJEvlv",
        "colab_type": "code",
        "outputId": "e78c3158-e42b-4f31-d9b3-62090927ba00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#split into words\n",
        "tokenized_words=[]\n",
        "tokenized_words.extend(word for word in word_tokenize(str(test_convo_1)))\n",
        "pp.pprint(tokenized_words[-10:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['back', 'to', 'you.Thanks', 'for', 'your', 'help', \"'\", ',', \"''\", ']']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWB3vDWsRt16",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Main code to run with functions\n",
        "list_of_convos = text_to_convo(convo_all)\n",
        "list_of_statements = convo_to_statement(list_of_convos)\n",
        "flat_convos = flatten_list(list_of_statements)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6F_mTQzFnSP",
        "colab_type": "text"
      },
      "source": [
        "## Punctuation & Lower Case"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmUhpSFsJcnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "string.punctuation = string.punctuation + '``' + '...'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3PxB5H4Qzwj",
        "colab_type": "code",
        "outputId": "3cb76cb1-badf-46d1-fe93-6be08ff06cf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "string.punctuation"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~``...``...'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGiIb7YfFsew",
        "colab_type": "code",
        "outputId": "5d413f29-97be-41a2-f581-df1244ff679e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Removes punctuation\n",
        "no_punct = [token for token in tokenized_words if token not in string.punctuation] \n",
        "print(no_punct[-10:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I', 'will', 'come', 'back', 'to', 'you.Thanks', 'for', 'your', 'help', \"''\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kN_v90X9OLCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "no_punct = [word.strip('\\'') for word in no_punct] # Pesky ' attatched to word\n",
        "no_punct = [word.replace('.',' ') for word in no_punct] # Pesky . attatched to word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ofBua-nGuYE",
        "colab_type": "code",
        "outputId": "64c836fc-8b7b-42b2-d044-71b6ae9410dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Lowercase text\n",
        "data_lower = [word.lower() for word in no_punct]\n",
        "print(data_lower[-10:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', 'will', 'come', 'back', 'to', 'you thanks', 'for', 'your', 'help', '']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvNQtNPVG49I",
        "colab_type": "text"
      },
      "source": [
        "## Stop Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgIaa9qiIuFP",
        "colab_type": "code",
        "outputId": "f54dd68b-cba3-4461-9a5b-1107f8e51155",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJUMTOcTIxZd",
        "colab_type": "code",
        "outputId": "49504190-f537-465a-8f42-a94c6a0aa234",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "stop_words = stopwords.words('english')\n",
        "add_stop_words = ['would','could']\n",
        "stop_words += add_stop_words\n",
        "print(stop_words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'would', 'could']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6gxeqbRIfQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filtered_word = []\n",
        "for word in data_lower:\n",
        "  if word not in stop_words:\n",
        "    filtered_word.append(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcosHlzldnYF",
        "colab_type": "code",
        "outputId": "a1abb6d9-2aa2-42af-805d-2e4c67e19858",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "filtered_word"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['like',\n",
              " 'book',\n",
              " 'trip',\n",
              " 'atlantis',\n",
              " 'caprica',\n",
              " 'saturday',\n",
              " 'august',\n",
              " '13',\n",
              " '2016',\n",
              " '8',\n",
              " 'adults',\n",
              " 'tight',\n",
              " 'budget',\n",
              " '1700',\n",
              " 'hi',\n",
              " 'checked',\n",
              " 'options',\n",
              " 'unfortunately',\n",
              " 'currently',\n",
              " 'trips',\n",
              " 'meet',\n",
              " 'criteria',\n",
              " 'like',\n",
              " 'book',\n",
              " 'alternate',\n",
              " 'travel',\n",
              " 'option',\n",
              " 'yes',\n",
              " 'going',\n",
              " 'neverland',\n",
              " 'caprica',\n",
              " 'august',\n",
              " '13',\n",
              " '2016',\n",
              " '5',\n",
              " 'adults',\n",
              " 'trip',\n",
              " 'budget',\n",
              " '1900',\n",
              " 'checked',\n",
              " 'availability',\n",
              " 'date',\n",
              " 'trips',\n",
              " 'available',\n",
              " 'like',\n",
              " 'select',\n",
              " 'alternate',\n",
              " 'dates',\n",
              " 'flexibility',\n",
              " 'dates',\n",
              " 'leave',\n",
              " 'atlantis',\n",
              " 'rather',\n",
              " 'caprica',\n",
              " 'checked',\n",
              " 'availability',\n",
              " 'date',\n",
              " 'trips',\n",
              " 'available',\n",
              " 'like',\n",
              " 'select',\n",
              " 'alternate',\n",
              " 'dates',\n",
              " 'suppose',\n",
              " 'speak',\n",
              " 'husband',\n",
              " 'see',\n",
              " 'choose',\n",
              " 'dates',\n",
              " 'come',\n",
              " 'back',\n",
              " 'you thanks',\n",
              " 'help',\n",
              " '']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IlAyS8PPVov",
        "colab_type": "text"
      },
      "source": [
        "### Emoji removal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GslwOGSgOgIa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for word in filtered_word[:]:       #makes a copy of the list words and then iterates over that copy. Then, modifies the original list.\n",
        "    if word.endswith('_face'): \n",
        "        filtered_word.remove(word) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdNT9auiRoKO",
        "colab_type": "text"
      },
      "source": [
        "## Stemming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJet3LjsJAjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stemmer = SnowballStemmer('english', ignore_stopwords=True) # Already removed stopwords"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwauVi_ZYpDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stemmed_words = []\n",
        "\n",
        "for words in filtered_sent:\n",
        "  \n",
        "  stemmed_words.append(stemmer.stem(words)) \n",
        "\n",
        "  print('Words '+words+' - stemmer:'+stemmer.stem(words))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Z20xkS5uSJ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filtered_words = []\n",
        "for word in stemmed_words:\n",
        "  if word not in stop_words:\n",
        "    filtered_words.append(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fE0Dx67u5Qq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filtered_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpQCZqm1u8Rp",
        "colab_type": "text"
      },
      "source": [
        "## Lemmatizing with appropriate POS tag"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUnoQv-mzbfT",
        "colab_type": "code",
        "outputId": "c7224264-413c-4855-bd78-accb79f74cd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "nltk.download('wordnet')                        # Lemmatization\n",
        "nltk.download('averaged_perceptron_tagger')     # POS tagging"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CV6dH8mA0zV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_wordnet_pos(word):\n",
        "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "\n",
        "    return tag_dict.get(tag, wordnet.NOUN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXmXofCZA7a_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lem_words = []\n",
        "lem = WordNetLemmatizer()\n",
        "lem_words = [lem.lemmatize(word, get_wordnet_pos(word)) for word in filtered_word if word]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7s7HwBPUPHMV",
        "colab_type": "code",
        "outputId": "0aaa5847-ed62-4142-e627-deb41251fbea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "lem_words[-10:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['suppose',\n",
              " 'speak',\n",
              " 'husband',\n",
              " 'see',\n",
              " 'choose',\n",
              " 'date',\n",
              " 'come',\n",
              " 'back',\n",
              " 'you thanks',\n",
              " 'help']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFm2B4ef16DS",
        "colab_type": "text"
      },
      "source": [
        "## NER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbeCJfPx5SzE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = en_core_web_sm.load()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liAePA-pGfTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = ' '.join(lem_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBf54P3g_gY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "convo_nlp = nlp(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szVMuC5rDKrN",
        "colab_type": "code",
        "outputId": "a58257a5-9087-4e42-a9ea-08b25585cd52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "labels = [ent.label_ for ent in convo_nlp.ents]\n",
        "Counter(labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'CARDINAL': 1, 'DATE': 4, 'PRODUCT': 2})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeCbrqtmDY5R",
        "colab_type": "code",
        "outputId": "0f71e25f-d122-4b06-f7cb-f6bcde763875",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#Print a random sentence from these conversations \n",
        "sentences = [x for x in convo_nlp.sents]\n",
        "print(sentences[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "like book trip atlantis caprica saturday august 13 2016 8 adult tight budget 1700 hi checked option unfortunately currently trip meet criterion like book alternate travel option yes go neverland caprica august 13 2016 5 adult trip budget 1900 checked\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QfN-ZlGJx2u",
        "colab_type": "code",
        "outputId": "214dda2c-b760-43e5-db54-2640886983fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        "displacy.render(convo_nlp, jupyter=True, style='ent', page=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
              "<html lang=\"en\">\n",
              "    <head>\n",
              "        <title>displaCy</title>\n",
              "    </head>\n",
              "\n",
              "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
              "<figure style=\"margin-bottom: 6rem\">\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">like book trip \n",
              "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    atlantis\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
              "</mark>\n",
              " caprica \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    saturday\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    august 13 2016 8\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " adult tight budget \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    1700\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " hi checked option unfortunately currently trip meet criterion like book alternate travel option yes go neverland caprica \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    august 13 2016 5\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " adult trip budget \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    1900\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " checked availability date trip available like select alternate date flexibility date leave \n",
              "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    atlantis\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
              "</mark>\n",
              " rather caprica checked availability date trip available like select alternate date suppose speak husband see choose date come back you thanks help</div>\n",
              "</figure>\n",
              "</body>\n",
              "</html></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvdBuHQtKXTG",
        "colab_type": "text"
      },
      "source": [
        "# Chatterbot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJ12G7U4ibb7",
        "colab_type": "code",
        "outputId": "d09e7bf9-c8ff-4301-fbbf-db344f6d6c94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Create a new chat bot named Charlie\n",
        "chatbot = ChatBot('Charlie')\n",
        "trainer = ListTrainer(chatbot)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50vn2vPxwteJ",
        "colab_type": "code",
        "outputId": "7eb330e6-1e08-4689-d80e-f380bb1d9b53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainer.train([\n",
        "    'How are you?',\n",
        "    'I am good.',\n",
        "    'That is good to hear.',\n",
        "    'Thank you',\n",
        "    'You are welcome.',\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "List Trainer: [####################] 100%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoOohofQ5sgJ",
        "colab_type": "code",
        "outputId": "672bae01-3b0c-45ea-c70c-c525344f6c4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainer.train(flat_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "List Trainer: [####################] 100%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzLGP8kKsBmG",
        "colab_type": "code",
        "outputId": "83ff2809-129d-4816-c043-e549b2b259f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(chatbot.get_response('Hi'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "To start, just give me some information on where you would like to travel, your budget, your point of departure, or any other travel info you can think of.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVG3GUofrJ24",
        "colab_type": "code",
        "outputId": "0683069c-d081-4b26-b7ae-18f900ee6e3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(chatbot.get_response('I would like to travel from Toronto to Japan'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Did you have any specific dates in mind?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPTYd5-j7_C1",
        "colab_type": "code",
        "outputId": "f3529a0f-593c-4a84-f376-11f69f9c625c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(chatbot.get_response('June to August'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "How much would that be?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9-q63wu8JRS",
        "colab_type": "code",
        "outputId": "31619179-dc76-4848-a04d-d3ae9cb11280",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(chatbot.get_response('under 1200'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Perfect. Thank you.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhAhlBR68NOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}